{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from whole_brain_model import WholeBrainModel, ModelParams\n",
    "# from model_fitting import ModelFitting\n",
    "# from costs import Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "\n",
    "    def check_for_nans(tensor, name=\"Tensor\"):\n",
    "        \"\"\"\n",
    "        Checks if a tensor contains NaNs\n",
    "        Error message or Min / Max if not\n",
    "        \"\"\"\n",
    "        if torch.isnan(tensor).any():\n",
    "            print(f\"[ERROR] {name} contains NaNs!\")\n",
    "        else:\n",
    "            print(f\"[DEBUG] {name} OK. Min: {tensor.min().item():.4f}, Max: {tensor.max().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, fmri_filename: str, dti_filename: str, chunk_length: int = 50):\n",
    "        \"\"\"\n",
    "        Loads fMRI and DTI (SC) data, splits BOLD time series into chunks\n",
    "        \"\"\"\n",
    "        self.fmri_filename = fmri_filename\n",
    "        self.dti_filename = dti_filename\n",
    "        self.chunk_length = chunk_length\n",
    "        self.all_bold = []  # list of BOLD arrays, each shape (node_size, num_TRs)\n",
    "        self.all_SC = []    # list of SC matrices, each shape (node_size, node_size)\n",
    "        self.bold_chunks = []  # list of dicts: {'subject': int, 'bold': array (node_size, chunk_length)}\n",
    "        \n",
    "        self.load_data()\n",
    "        self.split_into_chunks()\n",
    "\n",
    "    def load_data(self):\n",
    "        fmri_mat = scipy.io.loadmat(self.fmri_filename)\n",
    "        dti_mat = scipy.io.loadmat(self.dti_filename)\n",
    "        bold_data = fmri_mat[\"BOLD_timeseries_HCP\"]    # shape (100, 1)\n",
    "        dti_data = dti_mat[\"DTI_fibers_HCP\"]           # shape (100, 1)\n",
    "        num_subjects = bold_data.shape[0]\n",
    "        \n",
    "        for subject in range(num_subjects):\n",
    "            bold_subject = bold_data[subject, 0]  # shape (100, 1189)\n",
    "            dti_subject = dti_data[subject, 0]    # shape (100, 100)\n",
    "            self.all_bold.append(bold_subject)\n",
    "            \n",
    "            # Process SC: symmetric, log-transform, normalise\n",
    "            SC = 0.5 * (dti_subject.T + dti_subject)\n",
    "            SC = np.log1p(SC) / np.linalg.norm(np.log1p(SC))\n",
    "            self.all_SC.append(SC)\n",
    "        print(f\"[DataLoader] Loaded {num_subjects} subjects.\")\n",
    "\n",
    "    def split_into_chunks(self):\n",
    "        self.bold_chunks = []\n",
    "        for subject, bold_subject in enumerate(self.all_bold):\n",
    "            num_TRs = bold_subject.shape[1]\n",
    "            num_chunks = num_TRs // self.chunk_length\n",
    "            for i in range(num_chunks):\n",
    "                chunk = bold_subject[:, i*self.chunk_length:(i+1)*self.chunk_length]\n",
    "                self.bold_chunks.append({\"subject\": subject, \"bold\": chunk})\n",
    "        print(f\"[DataLoader] Created {len(self.bold_chunks)} chunks (chunk length = {self.chunk_length}).\")\n",
    "\n",
    "    def sample_minibatch(self, batch_size: int):\n",
    "        sampled = random.sample(self.bold_chunks, batch_size)\n",
    "        batched_bold = []\n",
    "        batched_SC = []\n",
    "        for batch_element in sampled:\n",
    "            batched_bold.append(batch_element[\"bold\"]) # (node_size, chunk_length)\n",
    "            subject = batch_element[\"subject\"]\n",
    "            SC = self.all_SC[subject]\n",
    "\n",
    "            # NOTE: Test with non-Laplacian SC\n",
    "            D = np.diag(np.sum(SC, axis=1))\n",
    "            L = D - SC\n",
    "            batched_SC.append(L)\n",
    "\n",
    "            # self.plot_laplacian(subject, L)\n",
    "\n",
    "        # Stack BOLD\n",
    "        batched_bold = np.stack(batched_bold, axis=-1) # (node_size, chunk_length, batch_size)\n",
    "        batched_bold = torch.tensor(batched_bold, dtype=torch.float32)\n",
    "\n",
    "        # Stack batched SC\n",
    "        batched_SC = np.stack(batched_SC, axis=0)\n",
    "        batched_SC = torch.tensor(batched_SC, dtype=torch.float32)\n",
    "\n",
    "        return batched_bold, batched_SC, sampled\n",
    "\n",
    "    def plot_laplacian(self, subject: int, L: np.ndarray):\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(L, cmap='viridis')\n",
    "        plt.title(f\"Laplacian Heatmap (Subject {subject})\")\n",
    "        plt.xlabel(\"ROI index\")\n",
    "        plt.ylabel(\"ROI index\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Costs:\n",
    "    \n",
    "    def plot_time_series(self, time_series, title=\"Time Series\"):\n",
    "        \"\"\"\n",
    "        Plots batched BOLD time series on single plot:\n",
    "        \n",
    "        time_series: torch.Tensor, shape (N, T, B)\n",
    "        \"\"\"\n",
    "        if isinstance(time_series, torch.Tensor):\n",
    "            time_series = time_series.detach().cpu().numpy()\n",
    "        N, T, B = time_series.shape\n",
    "        for batch in range(B):\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for i in range(min(6, N)):  # plot first 6 nodes for clarity\n",
    "                plt.plot(np.arange(T), time_series[i, :, batch], label=f'Node {i}')\n",
    "            plt.title(f'{title} - Batch Element {batch}')\n",
    "            plt.xlabel('Time Step')\n",
    "            plt.ylabel('BOLD signal')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_fc(self, sim_fc, emp_fc):\n",
    "        \"\"\"\n",
    "        Plots both simulated and empirical Functional Connectivity (heatmap) on horizontal axis\n",
    "\n",
    "        sim_fc, emp_fc: np.ndarray\n",
    "        \"\"\"\n",
    "        ## Visualisations\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "        # Plot simulated FC matrix\n",
    "        im1 = ax1.imshow(sim_fc, vmin=-1, vmax=1, cmap='coolwarm')\n",
    "        ax1.set_title(\"Simulated FC\")\n",
    "        plt.colorbar(im1, ax=ax1)\n",
    "\n",
    "        im2 = ax2.imshow(emp_fc, vmin=-1, vmax=1, cmap='coolwarm')\n",
    "        ax2.set_title(\"Empirical FC\")\n",
    "        plt.colorbar(im2, ax=ax2)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def compare_bold(self, simulated_bold, empirical_bold, plot=True, verbose=True):\n",
    "        \"\"\"\n",
    "        Compare two BOLD time series and calcuate Pearson correlation between FC matrices\n",
    "\n",
    "        Parameters:\n",
    "            simulated_bold: torch.Tensor shape (N, T, B)\n",
    "            empirical_bold: torch.Tensor shape (N, T, B)\n",
    "\n",
    "        Returns:\n",
    "            correlation_loss: torch scalar, Pearson's correlation loss between FC matrices\n",
    "                calculated as -log(0.5 + 0.5 * global_corr)\n",
    "        \"\"\"\n",
    "        if not isinstance(simulated_bold, torch.Tensor):\n",
    "            simulated_bold = torch.tensor(simulated_bold, dtype=torch.float32)\n",
    "        if not isinstance(empirical_bold, torch.Tensor):\n",
    "            empirical_bold = torch.tensor(empirical_bold, dtype=torch.float32)\n",
    "        \n",
    "        assert simulated_bold.shape == empirical_bold.shape, f\"Simulated and Empirical BOLD time series must have the same dimensions. Found EMP: {empirical_bold.shape}, SIM: {simulated_bold.shape}\"\n",
    "        print(f\"Simulated BOLD shape: ({simulated_bold.shape})\")\n",
    "        N, T, B = simulated_bold.shape\n",
    "\n",
    "        rmse = torch.sqrt(torch.mean((simulated_bold - empirical_bold) ** 2))\n",
    "\n",
    "        # Compute Pearon's correlation between per node\n",
    "        rois_correlation = []\n",
    "        for b in range(B):\n",
    "            batch_correlation = []\n",
    "            for node in range(N):\n",
    "                sim = simulated_bold[node, :, b]\n",
    "                emp = empirical_bold[node, :, b]\n",
    "\n",
    "                # Zero mean\n",
    "                s_centered = sim - torch.mean(sim)\n",
    "                e_centered = emp - torch.mean(emp)\n",
    "                corr = torch.dot(s_centered, e_centered) / (torch.sqrt(torch.sum(s_centered**2)) * torch.sqrt(torch.sum(e_centered**2)) + 1e-8)\n",
    "                batch_correlation.append(corr)\n",
    "\n",
    "            rois_corr_b = torch.stack(batch_correlation)\n",
    "            rois_correlation.append(torch.mean(rois_corr_b))\n",
    "            \n",
    "        average_rois_correlation = torch.mean(torch.stack(rois_correlation))\n",
    "\n",
    "        global_corrs = []\n",
    "        for b in range(B):\n",
    "            sim_b = simulated_bold[:, :, b]\n",
    "            emp_b = empirical_bold[:, :, b]\n",
    "        \n",
    "            # Compute global FC matrices\n",
    "            sim_n = sim_b - torch.mean(sim_b, dim=1, keepdim=True)\n",
    "            emp_n = emp_b - torch.mean(emp_b, dim=1, keepdim=True)\n",
    "            cov_sim = sim_n @ sim_n.t()  # (N, N)\n",
    "            cov_emp = emp_n @ emp_n.t()  # (N, N)\n",
    "            std_sim = torch.sqrt(torch.diag(cov_sim) + 1e-8)\n",
    "            std_emp = torch.sqrt(torch.diag(cov_emp) + 1e-8)\n",
    "            FC_sim = cov_sim / (std_sim.unsqueeze(1) * std_sim.unsqueeze(0) + 1e-8)\n",
    "            FC_emp = cov_emp / (std_emp.unsqueeze(1) * std_emp.unsqueeze(0) + 1e-8)\n",
    "            \n",
    "            # Extract lower triangular parts (excluding the diagonal)\n",
    "            mask = torch.tril(torch.ones_like(FC_sim), diagonal=-1).bool()\n",
    "            sim_vec = FC_sim[mask]\n",
    "            emp_vec = FC_emp[mask]\n",
    "            sim_vec = sim_vec - torch.mean(sim_vec)\n",
    "            emp_vec = emp_vec - torch.mean(emp_vec)\n",
    "            \n",
    "            global_corr_b = torch.sum(sim_vec * emp_vec) / (torch.sqrt(torch.sum(sim_vec**2)) * torch.sqrt(torch.sum(emp_vec**2)) + 1e-8)\n",
    "            global_corrs.append(global_corr_b)\n",
    "        \n",
    "        global_corr = torch.mean(torch.stack(global_corrs))\n",
    "\n",
    "        if plot:\n",
    "            FC_sim_np = FC_sim.detach().cpu().numpy()\n",
    "            FC_emp_np = FC_emp.detach().cpu().numpy()\n",
    "\n",
    "            self.plot_fc(FC_sim_np, FC_emp_np)\n",
    "\n",
    "        if verbose:\n",
    "\n",
    "            print(f\"RMSE between BOLD time series: {rmse:.4f}\")\n",
    "            print(f\"Average per-ROI Pearson correlation: {average_rois_correlation:.4f}\")\n",
    "            print(f\"FC Pearson's correlation: {global_corr:.4f}\")\n",
    "\n",
    "        correlation_loss = -torch.log(0.5 + 0.5 * global_corr + 1e-8)\n",
    "        return correlation_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParams:\n",
    "    def __init__(self):\n",
    "        ## DMF parameters\n",
    "        #  starting states taken from Griffiths et al. 2022\n",
    "        self.W_E    = 1.0               # Scale for external input to excitatory population\n",
    "        self.W_I    = 0.7               # Scale for external input to inhibitory population\n",
    "        self.I_0     = 0.32             # Constant external input\n",
    "        self.tau_E  = 100.0             # Decay time (ms) for excitatory synapses\n",
    "        self.tau_I  = 10.0              # Decay time for inhibitory synapses\n",
    "        self.gamma_E = 0.641 / 1000.0   # Kinetic parameter for excitatory dynamics\n",
    "\n",
    "        # Sigmoid parameters for conversion of current to firing rate:\n",
    "        self.aE     = 310.0\n",
    "        self.bE     = 125.0\n",
    "        self.dE     = 0.16\n",
    "        self.aI     = 615.0\n",
    "        self.bI     = 177.0\n",
    "        self.dI     = 0.087\n",
    "\n",
    "        # Connectivity parameters\n",
    "        self.g      = 20.0              # Global coupling (long-range)\n",
    "        self.g_EE   = 0.1               # Local excitatory self-feedback\n",
    "        self.g_IE   = 0.1               # Inhibitory-to-excitatory coupling\n",
    "        self.g_EI   = 0.1               # Excitatory-to-inhibitory coupling\n",
    "\n",
    "        ## Balloon (haemodynamic) parameters\n",
    "        self.tau_s  = 0.65\n",
    "        self.tau_f  = 0.41\n",
    "        self.tau_0  = 0.98\n",
    "        self.alpha  = 0.32\n",
    "        self.rho    = 0.34\n",
    "        self.k1     = 2.38\n",
    "        self.k2     = 2.0\n",
    "        self.k3     = 0.48\n",
    "        self.V      = 0.02      # V0 in the BOLD equation\n",
    "        self.E0     = 0.34\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Whole Brain Model integrating both DMF and Balloon\n",
    "class WholeBrainModel(nn.Module):\n",
    "    def __init__(self, params: ModelParams, input_size: int, node_size: int, batch_size: int, \n",
    "                 step_size: float, tr: float):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            params: ModelParams container (attributes W_E, tau_E, gamma_E, ...)\n",
    "            input_size: Number of inptu channels (e.g. noise channels) per integration step\n",
    "            node_size: Number of nodes (ROIs)\n",
    "            batch_size: Batch size (number of parallel simulations)\n",
    "            step_size: Integration time steps (0.05s)\n",
    "            tr: TR duation (0.75s); hidden_size = tr / step_size\n",
    "\n",
    "        \"\"\"\n",
    "        super(WholeBrainModel, self).__init__()\n",
    "        self.node_size = node_size\n",
    "        self.batch_size = batch_size\n",
    "        self.step_size = step_size\n",
    "        self.tr = tr\n",
    "        self.hidden_size = int(tr / step_size)  # number of integration steps per TR\n",
    "        self.input_size = input_size  # noise input dimension\n",
    "\n",
    "        self.state_size = 6  # [E, I, x, f, v, q]\n",
    "\n",
    "        # DMF parameters\n",
    "        self.W_E    = nn.Parameter(torch.tensor(params[\"W_E\"], dtype=torch.float32))\n",
    "        self.W_I    = nn.Parameter(torch.tensor(params[\"W_I\"], dtype=torch.float32))\n",
    "        self.I_0     = nn.Parameter(torch.tensor(params[\"I_0\"], dtype=torch.float32))\n",
    "        self.tau_E  = nn.Parameter(torch.tensor(params[\"tau_E\"], dtype=torch.float32))\n",
    "        self.tau_I  = nn.Parameter(torch.tensor(params[\"tau_I\"], dtype=torch.float32))\n",
    "        self.gamma_E= nn.Parameter(torch.tensor(params[\"gamma_E\"], dtype=torch.float32))\n",
    "        self.aE     = nn.Parameter(torch.tensor(params[\"aE\"], dtype=torch.float32))\n",
    "        self.bE     = nn.Parameter(torch.tensor(params[\"bE\"], dtype=torch.float32))\n",
    "        self.dE     = nn.Parameter(torch.tensor(params[\"dE\"], dtype=torch.float32))\n",
    "        self.aI     = nn.Parameter(torch.tensor(params[\"aI\"], dtype=torch.float32))\n",
    "        self.bI     = nn.Parameter(torch.tensor(params[\"bI\"], dtype=torch.float32))\n",
    "        self.dI     = nn.Parameter(torch.tensor(params[\"dI\"], dtype=torch.float32))\n",
    "        self.g      = nn.Parameter(torch.tensor(params[\"g\"], dtype=torch.float32))\n",
    "        self.g_EE   = nn.Parameter(torch.tensor(params[\"g_EE\"], dtype=torch.float32))\n",
    "        self.g_IE   = nn.Parameter(torch.tensor(params[\"g_IE\"], dtype=torch.float32))\n",
    "        self.g_EI   = nn.Parameter(torch.tensor(params[\"g_EI\"], dtype=torch.float32))\n",
    "\n",
    "        # Balloon (hemodynamic) parameters\n",
    "        self.tau_s  = nn.Parameter(torch.tensor(params[\"tau_s\"], dtype=torch.float32))\n",
    "        self.tau_f  = nn.Parameter(torch.tensor(params[\"tau_f\"], dtype=torch.float32))\n",
    "        self.tau_0  = nn.Parameter(torch.tensor(params[\"tau_0\"], dtype=torch.float32))\n",
    "        self.alpha  = nn.Parameter(torch.tensor(params[\"alpha\"], dtype=torch.float32))\n",
    "        self.rho    = nn.Parameter(torch.tensor(params[\"rho\"], dtype=torch.float32))\n",
    "        self.k1     = nn.Parameter(torch.tensor(params[\"k1\"], dtype=torch.float32))\n",
    "        self.k2     = nn.Parameter(torch.tensor(params[\"k2\"], dtype=torch.float32))\n",
    "        self.k3     = nn.Parameter(torch.tensor(params[\"k3\"], dtype=torch.float32))\n",
    "        self.V      = nn.Parameter(torch.tensor(params[\"V\"], dtype=torch.float32))\n",
    "        self.E0     = nn.Parameter(torch.tensor(params[\"E0\"], dtype=torch.float32))\n",
    "\n",
    "        print(\"[DEBUG] Model initialized with state_size:\", self.state_size, \"hidden_size:\", self.hidden_size)\n",
    "\n",
    "    def generate_initial_states(self):\n",
    "        \"\"\"\n",
    "        Generates the initial state for RWW (DMF) foward function. Uses same initial states as in the Griffiths et al. code\n",
    "\n",
    "        Returns:\n",
    "            initial_state: torch.Tensor of shape (node_size, input_size, batch_size)\n",
    "        \"\"\"\n",
    "        initial_state = 0.45 * np.random.uniform(0, 1, (self.node_size, self.input_size, self.batch_size))\n",
    "        baseline = np.array([0, 0, 0, 1.0, 1.0, 1.0]).reshape(1, self.input_size, 1)\n",
    "        initial_state = initial_state + baseline\n",
    "        return torch.tensor(initial_state, dtype=torch.float32)\n",
    "\n",
    "    def h_tf(self, a, b, d, current):\n",
    "        \"\"\"\n",
    "        Transformation for firing rates of excitatory and inhibitory pools\n",
    "        Takes variables a, b, current and convert into a linear equation (a * current - b) while adding a small\n",
    "        amount of noise (1e-5) while dividing that term to an exponential of itself multiplied by constant d for\n",
    "        the appropriate dimensions\n",
    "        \"\"\"\n",
    "        num = 1e-5 + torch.abs(a * current - b)\n",
    "        den = 1e-5 * d + torch.abs(1.000 - torch.exp(-d * (a * current - b)))\n",
    "        return torch.divide(num, den + 1e-8)\n",
    "    \n",
    "\n",
    "    def forward(self, hx: torch.Tensor, noise_in: torch.Tensor, noise_out: torch.Tensor, delays: torch.Tensor, batched_laplacian: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Simulate on TR chunk\n",
    "        \n",
    "        Parameters:\n",
    "            hx: Current state input, shape (node_size, 6, batch_size)\n",
    "            noise_in: Noise tensor for state updates, shape (node_size, hidden_size, batch_size, input_size)\n",
    "            noise_out: Noise tensor for BOLD output, shape (node_size, batch_size)\n",
    "            delays: Delay buffer for E, shape (node_size, delays_max)\n",
    "            batched_laplacian: batched Laplacian tensor, shape (batch_size, node_size, node_size)\n",
    "        \n",
    "        Returns:\n",
    "            state: Updated state (node_size, 6, batch_size)\n",
    "            bold: Simulated BOLD signal (node_size, batch_size)\n",
    "            delays: Updated delay buffer\n",
    "        \"\"\"\n",
    "        dt = self.step_size\n",
    "        state = hx\n",
    "\n",
    "        # Loop over hidden integration steps (one TR)\n",
    "        for i in range(self.hidden_size):\n",
    "            noise_step = noise_in[:, i, :, :] # (node_size, input_size, batch_size)\n",
    "\n",
    "            # --- DMF update ---\n",
    "            E = state[:, 0:1, :] # (node_size, 1, batch_size)\n",
    "            I = state[:, 1:2, :] # (node_size, 1, batch_size)\n",
    "\n",
    "            # Compute delayed excitatory input\n",
    "            # delayed_E = torch.gather(delays, 1, torch.zeros_like(delays, dtype=torch.int64)) # (node_size, delays_max, batch_size)\n",
    "            # assert delayed_E.shape[0] == self.node_size and delayed_E.shape[2] == self.batch_size, \\\n",
    "            #     f\"[DEBUG] delayed_E shape mismatch: got {delayed_E.shape}, expected ({self.node_size}, delays_max, {self.batch_size})\"\n",
    "            # delayed_E = delayed_E.mean(dim=1, keepdim=True) # (node_size, 1, batch_size)\n",
    "\n",
    "            # Permute E from (node_size, 1, batch_size) -> (bach_size, node_size, 1)\n",
    "            E_b = E.permute(2, 0, 1)\n",
    "            connectivity_effect_b = torch.bmm(batched_laplacian, E_b) # (batch_size, node_size, 1)\n",
    "            connectivity_effect = connectivity_effect_b.permute(1, 2, 0)  # (node_size, 1, batch_size)\n",
    "\n",
    "\n",
    "            I_E = self.W_E * self.I_0 + self.g_EE * E + self.g * connectivity_effect - self.g_IE * I\n",
    "            I_I = self.W_I * self.I_0 + self.g_EI * E - I\n",
    "\n",
    "            R_E = self.h_tf(self.aE, self.bE, self.dE, I_E)\n",
    "            R_I = self.h_tf(self.aI, self.bI, self.dI, I_I)\n",
    "\n",
    "            dE = -E / self.tau_E + (1 - E) * self.gamma_E * R_E\n",
    "            dI = -I / self.tau_I + R_I\n",
    "\n",
    "            E_new = E + dt * dE + noise_step[:, 0:1, :]  # use first channel of noise for E\n",
    "            I_new = I + dt * dI + noise_step[:, 1:2, :]  # second channel for I\n",
    "\n",
    "            # --- Balloon Update ---\n",
    "            x = state[:, 2:3, :]\n",
    "            f = state[:, 3:4, :]\n",
    "            v = state[:, 4:5, :]\n",
    "            q = state[:, 5:6, :]\n",
    "\n",
    "            dx = E_new - torch.reciprocal(self.tau_s) * x - torch.reciprocal(self.tau_f) * (f - 1)\n",
    "            df = x\n",
    "            dv = (f - torch.pow(v, torch.reciprocal(self.alpha))) * torch.reciprocal(self.tau_0)\n",
    "            dq = (f * (1 - torch.pow(1 - self.rho, torch.reciprocal(f))) * torch.reciprocal(self.rho) \\\n",
    "                   - q * torch.pow(v, torch.reciprocal(self.alpha)) * torch.reciprocal(v+1e-8)) \\\n",
    "                     * torch.reciprocal(self.tau_0)\n",
    "            \n",
    "            x_new = x + dt * dx + noise_step[:, 2:3, :]\n",
    "            f_new = f + dt * df + noise_step[:, 3:4, :]\n",
    "            v_new = v + dt * dv + noise_step[:, 4:5, :]\n",
    "            q_new = q + dt * dq + noise_step[:, 5:6, :]\n",
    "\n",
    "            state = torch.cat([E_new, I_new, x_new, f_new, v_new, q_new], dim=1)\n",
    "\n",
    "            # Discard oldest delay value. Shape (node_size, delays_max, batch_size)\n",
    "            delays = torch.cat([E_new, delays[:, :-1, :]], dim=1)\n",
    "\n",
    "        BOLD = self.V * (self.k1 * (1 - q_new) + \\\n",
    "                        (self.k2 * (1 - q_new * torch.reciprocal(v_new))) + \\\n",
    "                        (self.k3 * (1 - v_new)))\n",
    "        BOLD = BOLD.squeeze(1)\n",
    "        BOLD = BOLD + noise_out\n",
    "\n",
    "        Utils.check_for_nans(BOLD, \"BOLD time series\")\n",
    "\n",
    "        # print(f\"[DEBUG] BOLD shape: {BOLD.shape} (expected ({self.node_size}, {self.batch_size}))\")\n",
    "\n",
    "        return state, BOLD, delays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelFitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anish Kochhar, Imperial College London, March 2025\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ModelFitting:\n",
    "    def __init__(self, model: WholeBrainModel, empirical_bold: torch.Tensor, num_epochs: int, lr: float, cost_function, log_state: bool = False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            model: WholeBrainModel instance\n",
    "            empirical_bold: Empirical BOLD data as torch tensor of float32 of shape (node_size, num_TRs, batch_size)\n",
    "            num_epochs: Number of training epochs\n",
    "            lr: Learning rate\n",
    "            cost_function: Cost function for comparision between simulated and empirical BOLD\n",
    "            log_state: If True, logs the evolution of state variables over TR chunks\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.empirical_bold = empirical_bold\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.cost_function = cost_function # Costs.compare_bold\n",
    "        self.log_state = log_state\n",
    "\n",
    "        self.logs = { \"state_means\": [], \"losses\": [] }\n",
    "\n",
    "    def train(self, initial_state: torch.Tensor, initial_delays: torch.Tensor, batched_laplacian: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Train the model by iterating of TR chunks\n",
    "\n",
    "        Parameters:\n",
    "            initial_state: Initial state tensor of shape (node_size, 6, batch_size)\n",
    "            initial_delays: Initial delay buffer of shape (node_size, delays_max, batch_size)\n",
    "            batched_laplacian: Batched Laplacian tensor of shape (batch_size, node_size, node_size)\n",
    "            \n",
    "        Returns:\n",
    "            loss_history: List of loss values per epoch.\n",
    "            simulated_bold: Simulated BOLD time series (node_size, num_TRs, batch_size)\n",
    "        \"\"\"\n",
    "        num_TRs = self.empirical_bold.shape[1]\n",
    "        loss_history = []\n",
    "\n",
    "        state = initial_state\n",
    "        delays = initial_delays\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            simulated_bold_chunks = []\n",
    "            epoch_state_log = []\n",
    "\n",
    "            for tr_index in range(num_TRs):\n",
    "                # -- Generate noise for integration steps --\n",
    "                # noise_in shape: (node_size, hidden_size, batch_size, input_size) with input_size = 6\n",
    "                noise_in = torch.randn(self.model.node_size, self.model.hidden_size, self.model.input_size, self.model.batch_size) * 0.02\n",
    "                # noise_out shape: (node_size, batch_size)\n",
    "                noise_out = torch.randn(self.model.node_size, self.model.batch_size) * 0.02\n",
    "\n",
    "                state, bold_chunk, delays = self.model(state, noise_in, noise_out, delays, batched_laplacian)\n",
    "                simulated_bold_chunks.append(bold_chunk)\n",
    "\n",
    "                if self.log_state:\n",
    "                    state_mean = torch.mean(state, dim=(0, 2)).detach().cpu().numpy()\n",
    "                    epoch_state_log.append(state_mean)\n",
    "\n",
    "            # Stack TR chunks to form a time series: (node_size, num_TRs, batch_size)\n",
    "            simulated_bold_epoch = torch.stack(simulated_bold_chunks, dim=1)\n",
    "\n",
    "            state = state.detach()  # Avoid backprop through the entire history\n",
    "            delays = delays.detach()\n",
    "\n",
    "            # Compute cost \n",
    "            loss = self.cost_function(simulated_bold_epoch, self.empirical_bold)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            epoch_loss = loss.item()\n",
    "            loss_history.append(epoch_loss)\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "            if self.log_state:\n",
    "                self.logs[\"state_means\"].append(np.array(epoch_state_log))\n",
    "            self.logs[\"losses\"].append(epoch_loss)\n",
    "\n",
    "        # Return time series from last epoch\n",
    "        simulated_bold_all = simulated_bold_epoch.detach().cpu().numpy()\n",
    "\n",
    "        return loss_history, simulated_bold_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataLoader] Loaded 100 subjects.\n",
      "[DataLoader] Created 2300 chunks (chunk length = 50).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fmri_filename = \"../HCP Data/BOLD Timeseries HCP.mat\"\n",
    "dti_filename = \"../HCP Data/DTI Fibers HCP.mat\"\n",
    "\n",
    "\n",
    "data_loader = DataLoader(fmri_filename, dti_filename, chunk_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Main] Empirical BOLD batch shape: torch.Size([100, 50, 4])\n",
      "[Main] Batched SC shape: torch.Size([4, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4  # mini-batch size\n",
    "empirical_bold_batch, batched_SC, sampled_entries = data_loader.sample_minibatch(batch_size)\n",
    "# empirical_bold_batch: shape (node_size, chunk_length, batch_size)\n",
    "print(f\"[Main] Empirical BOLD batch shape: {empirical_bold_batch.shape}\")\n",
    "print(f\"[Main] Batched SC shape: {batched_SC.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Settings\n",
    "node_size = batched_SC.shape[1]         # 100\n",
    "batch_size = 4                          # Minibatch size\n",
    "step_size = 0.05                        # Integration time step\n",
    "tr = 0.75                               # TR duration\n",
    "input_size = 6                          # Number of noise channels\n",
    "delays_max = 100                        # Maximum delay time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Model initialized with state_size: 6 hidden_size: 15\n"
     ]
    }
   ],
   "source": [
    "params = ModelParams()\n",
    "\n",
    "model = WholeBrainModel(params, input_size, node_size, batch_size, step_size, tr)\n",
    "\n",
    "costs = Costs()\n",
    "\n",
    "# Initial states and delays\n",
    "initial_state = model.generate_initial_states()\n",
    "initial_delays = torch.zeros(node_size, delays_max, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelFitting(model, empirical_bold=empirical_bold_batch, num_epochs=10, lr=0.001, cost_function=costs.compare_bold, log_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, simulated_bold = trainer.train(initial_state, initial_delays, batched_SC)\n",
    "\n",
    "print(\"[Main] Training complete\")\n",
    "print(\"[Main] Simulated BOLD shape:\", simulated_bold.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
